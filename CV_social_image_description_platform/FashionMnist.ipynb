{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook trying to invest the Kaggle dataset fashion mnist\n",
    "\n",
    "### Import Dog Dataset\n",
    "\n",
    "In the code cell below, I import a dataset of fashion-mnist images.  We populate a few variables through the use of the `mnist_reader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 60000 Train Images\n",
      "There are total 10000 Testing Images\n",
      "The size of the image is 784 pixels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./fashion-mnist/utils')\n",
    "import mnist_reader\n",
    "\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist(\\\n",
    "\t'./fashion-mnist/data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist(\\\n",
    "\t'./fashion-mnist/data/fashion', kind='t10k')\n",
    "\n",
    "print('There are total %d Train Images' % len(y_train))\n",
    "print('There are total %d Testing Images' % len(y_test))\n",
    "print('The size of the image is %d pixels' % X_train[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "where nb_samples corresponds to the total number of images (or samples), and rows, columns, and channels correspond to the number of rows, columns, and channels for each image, respectively.\n",
    "The path_to_tensor function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN. The function first loads the image and resizes it to a square image that is $28 \\times 28$ pixels. Next, the image is converted to an array, which is then resized to a 4D tensor. In this case, since we are working with gray images, each image has one channel. Likewise, since we are processing total images (or sample), the returned tensor will always have shape\n",
    "$$\n",
    "(60000, 224, 224, 1).\n",
    "$$\n",
    "\n",
    "The rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "train set:  (60000, 28, 28, 1)\n",
      "test set:  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "print (y_train.shape) # (n_samples, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "print(\"train set: \", X_train.shape) # (n_samples, 28, 28, 1)\n",
    "print(\"test set: \", X_test.shape) \n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# print (X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Using 30% of the training data as a validation set to optimizd the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train,\\\n",
    "                                                                y_train,\\\n",
    "                                                               test_size=0.3,\\\n",
    "                                                               random_state=123)\n",
    "# print(y_validation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model Architecture from scratch\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7, 7, 128)         16512     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 110,474\n",
      "Trainable params: 110,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same',\\\n",
    "                 input_shape = X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\\\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "Use the model checkpointing to save the model that attains the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10084 samples, validate on 4322 samples\n",
      "Epoch 1/50\n",
      "Epoch 00000: val_loss improved from inf to 1.07303, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "24s - loss: 1.0948 - acc: 0.5625 - val_loss: 1.0730 - val_acc: 0.5821\n",
      "Epoch 2/50\n",
      "Epoch 00001: val_loss improved from 1.07303 to 0.92692, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "24s - loss: 1.0337 - acc: 0.5952 - val_loss: 0.9269 - val_acc: 0.6798\n",
      "Epoch 3/50\n",
      "Epoch 00002: val_loss did not improve\n",
      "26s - loss: 0.9642 - acc: 0.6285 - val_loss: 0.9533 - val_acc: 0.6400\n",
      "Epoch 4/50\n",
      "Epoch 00003: val_loss improved from 0.92692 to 0.88057, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.9263 - acc: 0.6474 - val_loss: 0.8806 - val_acc: 0.6772\n",
      "Epoch 5/50\n",
      "Epoch 00004: val_loss improved from 0.88057 to 0.77735, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "26s - loss: 0.8827 - acc: 0.6694 - val_loss: 0.7773 - val_acc: 0.7233\n",
      "Epoch 6/50\n",
      "Epoch 00005: val_loss improved from 0.77735 to 0.76421, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "28s - loss: 0.8649 - acc: 0.6719 - val_loss: 0.7642 - val_acc: 0.7379\n",
      "Epoch 7/50\n",
      "Epoch 00006: val_loss did not improve\n",
      "27s - loss: 0.8263 - acc: 0.6920 - val_loss: 0.7942 - val_acc: 0.7149\n",
      "Epoch 8/50\n",
      "Epoch 00007: val_loss improved from 0.76421 to 0.73941, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "29s - loss: 0.8065 - acc: 0.6968 - val_loss: 0.7394 - val_acc: 0.7383\n",
      "Epoch 9/50\n",
      "Epoch 00008: val_loss improved from 0.73941 to 0.70146, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "28s - loss: 0.7713 - acc: 0.7132 - val_loss: 0.7015 - val_acc: 0.7503\n",
      "Epoch 10/50\n",
      "Epoch 00009: val_loss improved from 0.70146 to 0.69207, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.7628 - acc: 0.7130 - val_loss: 0.6921 - val_acc: 0.7543\n",
      "Epoch 11/50\n",
      "Epoch 00010: val_loss improved from 0.69207 to 0.64629, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "26s - loss: 0.7489 - acc: 0.7151 - val_loss: 0.6463 - val_acc: 0.7663\n",
      "Epoch 12/50\n",
      "Epoch 00011: val_loss did not improve\n",
      "28s - loss: 0.7308 - acc: 0.7250 - val_loss: 0.6566 - val_acc: 0.7497\n",
      "Epoch 13/50\n",
      "Epoch 00012: val_loss did not improve\n",
      "32s - loss: 0.7155 - acc: 0.7335 - val_loss: 0.6577 - val_acc: 0.7670\n",
      "Epoch 14/50\n",
      "Epoch 00013: val_loss improved from 0.64629 to 0.60306, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.7049 - acc: 0.7380 - val_loss: 0.6031 - val_acc: 0.7737\n",
      "Epoch 15/50\n",
      "Epoch 00014: val_loss did not improve\n",
      "27s - loss: 0.6980 - acc: 0.7383 - val_loss: 0.6336 - val_acc: 0.7640\n",
      "Epoch 16/50\n",
      "Epoch 00015: val_loss did not improve\n",
      "29s - loss: 0.6850 - acc: 0.7377 - val_loss: 0.6484 - val_acc: 0.7723\n",
      "Epoch 17/50\n",
      "Epoch 00016: val_loss did not improve\n",
      "28s - loss: 0.6780 - acc: 0.7458 - val_loss: 0.6179 - val_acc: 0.7735\n",
      "Epoch 18/50\n",
      "Epoch 00017: val_loss did not improve\n",
      "28s - loss: 0.6605 - acc: 0.7544 - val_loss: 0.6054 - val_acc: 0.7642\n",
      "Epoch 19/50\n",
      "Epoch 00018: val_loss did not improve\n",
      "27s - loss: 0.6504 - acc: 0.7547 - val_loss: 0.6124 - val_acc: 0.7830\n",
      "Epoch 20/50\n",
      "Epoch 00019: val_loss did not improve\n",
      "26s - loss: 0.6395 - acc: 0.7648 - val_loss: 0.7111 - val_acc: 0.7436\n",
      "Epoch 21/50\n",
      "Epoch 00020: val_loss did not improve\n",
      "29s - loss: 0.6330 - acc: 0.7652 - val_loss: 0.6083 - val_acc: 0.7793\n",
      "Epoch 22/50\n",
      "Epoch 00021: val_loss improved from 0.60306 to 0.56190, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "28s - loss: 0.6204 - acc: 0.7681 - val_loss: 0.5619 - val_acc: 0.7982\n",
      "Epoch 23/50\n",
      "Epoch 00022: val_loss improved from 0.56190 to 0.56018, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "28s - loss: 0.6148 - acc: 0.7626 - val_loss: 0.5602 - val_acc: 0.8015\n",
      "Epoch 24/50\n",
      "Epoch 00023: val_loss improved from 0.56018 to 0.52541, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.6059 - acc: 0.7683 - val_loss: 0.5254 - val_acc: 0.8117\n",
      "Epoch 25/50\n",
      "Epoch 00024: val_loss did not improve\n",
      "27s - loss: 0.6039 - acc: 0.7711 - val_loss: 0.5523 - val_acc: 0.7950\n",
      "Epoch 26/50\n",
      "Epoch 00025: val_loss did not improve\n",
      "28s - loss: 0.5972 - acc: 0.7767 - val_loss: 0.5342 - val_acc: 0.8073\n",
      "Epoch 27/50\n",
      "Epoch 00026: val_loss did not improve\n",
      "27s - loss: 0.5853 - acc: 0.7819 - val_loss: 0.5570 - val_acc: 0.8036\n",
      "Epoch 28/50\n",
      "Epoch 00027: val_loss did not improve\n",
      "27s - loss: 0.5786 - acc: 0.7840 - val_loss: 0.5459 - val_acc: 0.8063\n",
      "Epoch 29/50\n",
      "Epoch 00028: val_loss did not improve\n",
      "30s - loss: 0.5660 - acc: 0.7867 - val_loss: 0.5799 - val_acc: 0.7904\n",
      "Epoch 30/50\n",
      "Epoch 00029: val_loss did not improve\n",
      "29s - loss: 0.5673 - acc: 0.7850 - val_loss: 0.5642 - val_acc: 0.7975\n",
      "Epoch 31/50\n",
      "Epoch 00030: val_loss improved from 0.52541 to 0.49737, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.5576 - acc: 0.7927 - val_loss: 0.4974 - val_acc: 0.8255\n",
      "Epoch 32/50\n",
      "Epoch 00031: val_loss improved from 0.49737 to 0.48582, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.5611 - acc: 0.7919 - val_loss: 0.4858 - val_acc: 0.8267\n",
      "Epoch 33/50\n",
      "Epoch 00032: val_loss did not improve\n",
      "28s - loss: 0.5504 - acc: 0.7950 - val_loss: 0.5199 - val_acc: 0.8221\n",
      "Epoch 34/50\n",
      "Epoch 00033: val_loss did not improve\n",
      "27s - loss: 0.5468 - acc: 0.7938 - val_loss: 0.5144 - val_acc: 0.8184\n",
      "Epoch 35/50\n",
      "Epoch 00034: val_loss did not improve\n",
      "30s - loss: 0.5343 - acc: 0.8004 - val_loss: 0.4864 - val_acc: 0.8290\n",
      "Epoch 36/50\n",
      "Epoch 00035: val_loss did not improve\n",
      "30s - loss: 0.5360 - acc: 0.8006 - val_loss: 0.5353 - val_acc: 0.8087\n",
      "Epoch 37/50\n",
      "Epoch 00036: val_loss improved from 0.48582 to 0.46539, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "29s - loss: 0.5356 - acc: 0.8036 - val_loss: 0.4654 - val_acc: 0.8369\n",
      "Epoch 38/50\n",
      "Epoch 00037: val_loss improved from 0.46539 to 0.46382, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "29s - loss: 0.5285 - acc: 0.8064 - val_loss: 0.4638 - val_acc: 0.8376\n",
      "Epoch 39/50\n",
      "Epoch 00038: val_loss did not improve\n",
      "27s - loss: 0.5232 - acc: 0.8063 - val_loss: 0.4876 - val_acc: 0.8265\n",
      "Epoch 40/50\n",
      "Epoch 00039: val_loss improved from 0.46382 to 0.44089, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.5123 - acc: 0.8096 - val_loss: 0.4409 - val_acc: 0.8484\n",
      "Epoch 41/50\n",
      "Epoch 00040: val_loss improved from 0.44089 to 0.44068, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.5122 - acc: 0.8090 - val_loss: 0.4407 - val_acc: 0.8466\n",
      "Epoch 42/50\n",
      "Epoch 00041: val_loss did not improve\n",
      "29s - loss: 0.5088 - acc: 0.8144 - val_loss: 0.4431 - val_acc: 0.8408\n",
      "Epoch 43/50\n",
      "Epoch 00042: val_loss improved from 0.44068 to 0.43282, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "26s - loss: 0.5024 - acc: 0.8119 - val_loss: 0.4328 - val_acc: 0.8466\n",
      "Epoch 44/50\n",
      "Epoch 00043: val_loss did not improve\n",
      "30s - loss: 0.5004 - acc: 0.8172 - val_loss: 0.4500 - val_acc: 0.8334\n",
      "Epoch 45/50\n",
      "Epoch 00044: val_loss did not improve\n",
      "28s - loss: 0.5003 - acc: 0.8161 - val_loss: 0.4334 - val_acc: 0.8484\n",
      "Epoch 46/50\n",
      "Epoch 00045: val_loss improved from 0.43282 to 0.42326, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "27s - loss: 0.4977 - acc: 0.8161 - val_loss: 0.4233 - val_acc: 0.8510\n",
      "Epoch 47/50\n",
      "Epoch 00046: val_loss improved from 0.42326 to 0.40741, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "28s - loss: 0.4891 - acc: 0.8209 - val_loss: 0.4074 - val_acc: 0.8584\n",
      "Epoch 48/50\n",
      "Epoch 00047: val_loss did not improve\n",
      "28s - loss: 0.4796 - acc: 0.8259 - val_loss: 0.4480 - val_acc: 0.8445\n",
      "Epoch 49/50\n",
      "Epoch 00048: val_loss did not improve\n",
      "27s - loss: 0.4740 - acc: 0.8230 - val_loss: 0.4171 - val_acc: 0.8582\n",
      "Epoch 50/50\n",
      "Epoch 00049: val_loss improved from 0.40741 to 0.39603, saving model to ./saved_model/weights.best.from_scrathc.hdf5\n",
      "29s - loss: 0.4836 - acc: 0.8212 - val_loss: 0.3960 - val_acc: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aba4777550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# epochs = 5\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./saved_model/weights.best.from_scrathc.hdf5',\\\n",
    "                              verbose=1, save_best_only=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation),\\\n",
    "         epochs=50, batch_size=200, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('./saved_model/weights.best.from_scrathc.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Try out the model on the test dataset of fashion-mnist images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(test, axis=0))) for test in X_test]\n",
    "\n",
    "# report test accuracy\n",
    "# test_accuracy = 100 * np.sum(np.array(predictions) == np.argmax(y_test,\\\n",
    "#                                                     axis=0)) / len(predictions)\n",
    "# print(\"Test accuracy: %.4f%%\" % test_accuracy)\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# print('Test loss: ', score[0])\n",
    "# print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 11.5500%\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "test_accuracy = 100 * np.sum(np.array(predictions) == np.argmax(y_test,\\\n",
    "                                                    axis=0)) / len(predictions)\n",
    "print(\"Test accuracy: %.4f%%\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
